#!/usr/bin/env python3
"""
Test script cho Rule-based Physics Classifier v·ªõi dataset CSV th·ª±c t·∫ø.

Script n√†y ki·ªÉm tra:
- Kh·∫£ nƒÉng ph√¢n lo·∫°i c√¢u h·ªèi v·∫≠t l√Ω t·ª´ file CSV
- T√≠nh ch√≠nh x√°c tr√™n dataset l·ªõn
- Ph√¢n t√≠ch chi ti·∫øt theo t·ª´ng lo·∫°i

Author: Physics Problem Solving System Team
Version: 4.0.0 - CSV Dataset Testing
"""

import pandas as pd
import re
from typing import Dict, List, Tuple

def classify_physics_question(question: str) -> str:
    """
    Ph√¢n lo·∫°i c√¢u h·ªèi v·∫≠t l√Ω d·ª±a tr√™n rules c·∫£i ti·∫øn ƒë·ªÉ ƒë·∫°t 100% accuracy.

    Args:
        question: C√¢u h·ªèi c·∫ßn ph√¢n lo·∫°i

    Returns:
        str: Lo·∫°i c√¢u h·ªèi (THEORY, PRACTICE, MULTIPLE_CHOICE)
    """
    if not question or not question.strip():
        return "THEORY"

    question_clean = question.strip()
    question_lower = question_clean.lower()

    # Priority 1: Check for multiple choice (highest priority)
    # Use more specific patterns to avoid false positives with ¬∞C, ¬∞F, etc.
    multiple_choice_patterns = [
        ' a)', ' b)', ' c)', ' d)',
        ' A)', ' B)', ' C)', ' D)',
        'a) ', 'b) ', 'c) ', 'd) ',
        'A) ', 'B) ', 'C) ', 'D) '
    ]

    # Check for multiple choice with proper context (space before or after)
    has_multiple_choice = False
    for pattern in multiple_choice_patterns:
        if pattern in question_clean:
            has_multiple_choice = True
            break

    # Additional check for patterns at start of options
    if not has_multiple_choice:
        # Look for patterns like ": A)" or "A)" at beginning of options
        mc_regex = r'[:\s][ABCD]\)\s'
        if re.search(mc_regex, question_clean):
            has_multiple_choice = True

    if has_multiple_choice:
        return "MULTIPLE_CHOICE"

    # Priority 2: Check for theory keywords FIRST (before practice)
    theory_keywords = [
        'l√† g√¨', 'ƒë·ªãnh nghƒ©a', 'kh√°i ni·ªám', 'gi·∫£i th√≠ch', 'm√¥ t·∫£', 'n√™u', 'tr√¨nh b√†y',
        'ƒë·ªãnh lu·∫≠t', 'nguy√™n l√Ω', 'hi·ªán t∆∞·ª£ng', 'b·∫£n ch·∫•t', 'ƒë·∫∑c ƒëi·ªÉm',
        'ph√¢n lo·∫°i', 'so s√°nh', 'ph√¢n bi·ªát', '·ª©ng d·ª•ng', 'vai tr√≤', '√Ω nghƒ©a',
        't·∫°i sao', 'v√¨ sao', 'nh∆∞ th·∫ø n√†o', 'ra sao', 'ph√¢n t√≠ch', 'm√¥ t·∫£ c∆° ch·∫ø',
        'ho·∫°t ƒë·ªông c·ªßa', 'nguy√™n l√Ω ho·∫°t ƒë·ªông', 'c∆° ch·∫ø ho·∫°t ƒë·ªông', 'h√£y gi·∫£i th√≠ch'
    ]

    # Check for theory keywords but exclude cases where it's part of calculation context
    has_theory_keywords = False
    for keyword in theory_keywords:
        if keyword in question_lower:
            # Special handling for "t√≠nh ch·∫•t" - check if it's in calculation context
            if keyword == 't√≠nh ch·∫•t':
                # If "t√≠nh" appears before "t√≠nh ch·∫•t", it's likely a calculation question
                if 't√≠nh' in question_lower and question_lower.find('t√≠nh') < question_lower.find('t√≠nh ch·∫•t'):
                    continue  # Skip this theory keyword
            has_theory_keywords = True
            break

    # Strong theory indicators - if found, return THEORY immediately
    if has_theory_keywords:
        return "THEORY"

    # Priority 3: Enhanced calculation/practice detection
    # Strong calculation verbs
    calc_verbs = ['t√≠nh', 't√¨m', 'x√°c ƒë·ªãnh', 't√≠nh to√°n', 'gi·∫£i', 'suy ra', 'h·ªèi']

    # Enhanced units and measurements
    units = [
        # Basic units
        'kg', 'm/s', 'm/s¬≤', 'newton', 'joule', 'watt', 'volt', 'ampere', 'ohm',
        'n', 'j', 'w', 'v', 'a', 'œâ', 'pa', 'hz', 'tesla', 'weber', 'henry', 'farad',
        # Length units
        'cm', 'mm', 'km', 'm', 'nm',
        # Temperature units
        '¬∞c', 'k', 'kelvin',
        # Pressure units
        'atm', 'pascal',
        # Volume units
        'l√≠t', 'l', 'ml',
        # Energy units
        'ev', 'cal', 'kcal',
        # Time units
        's', 'ms', 'min', 'h',
        # Angle units
        'rad/s', 'rad', '¬∞', 'ƒë·ªô'
    ]

    # Mathematical symbols and expressions
    math_symbols = ['=', '+', '-', '√ó', '√∑', '¬≤', '¬≥', '‚àö', 'œÄ', 'Œ±', 'Œ≤', 'Œ≥', 'Œª', 'Œº', 'œÅ', 'œÉ', 'œâ']

    # Enhanced calculation context
    calc_context = [
        'v·ªõi', 'khi', 'r∆°i', 'n√©m', 'dao ƒë·ªông', 'va ch·∫°m', 'quay', 'chuy·ªÉn ƒë·ªông',
        'kh·ªëi l∆∞·ª£ng', 'v·∫≠n t·ªëc', 'gia t·ªëc', 'l·ª±c', 'c√¥ng', 'c√¥ng su·∫•t', 'nƒÉng l∆∞·ª£ng',
        'nhi·ªát l∆∞·ª£ng', 'nhi·ªát ƒë·ªô', '√°p su·∫•t', 'th·ªÉ t√≠ch', 'ƒëi·ªán √°p', 'd√≤ng ƒëi·ªán',
        'ƒëi·ªán tr·ªü', 't·ª´ tr∆∞·ªùng', 'ƒëi·ªán tr∆∞·ªùng', 't·∫ßn s·ªë', 'chu k√¨', 'b∆∞·ªõc s√≥ng',
        'chi·ªÅu d√†i', 'b√°n k√≠nh', 'ƒë∆∞·ªùng k√≠nh', 'di·ªán t√≠ch', 'th·ªùi gian', 'kho·∫£ng c√°ch',
        'ƒë·ªô cao', 'g√≥c', 'bi√™n ƒë·ªô', 'pha', 'hi·ªáu ƒëi·ªán th·∫ø', 'c∆∞·ªùng ƒë·ªô', 'su·∫•t ƒëi·ªán ƒë·ªông',
        't·ª´ th√¥ng', 'ƒëi·ªán dung', 'ƒë·ªô c·ª©ng', 'h·ªá s·ªë', 'chi·∫øt su·∫•t', 'ti√™u c·ª±',
        'ƒë·ªô ph√≥ng ƒë·∫°i', 'c·∫£m ·ª©ng t·ª´', 'nƒÉng l∆∞·ª£ng li√™n k·∫øt', 'kh·ªëi l∆∞·ª£ng ngh·ªâ',
        'ƒë·ªông l∆∞·ª£ng', 'xung l∆∞·ª£ng', 'momen', 'entropy', 'hi·ªáu su·∫•t'
    ]

    # Enhanced numerical patterns
    has_numbers_with_units = bool(re.search(r'\d+\s*[a-zA-ZŒ±-œâŒ©¬∞]+', question_clean))
    has_formula = bool(re.search(r'[a-zA-ZŒ±-œâŒ©]\s*=\s*[a-zA-ZŒ±-œâŒ©]', question_clean))
    has_calculation = bool(re.search(r'\d+\s*[+\-√ó√∑]\s*\d+', question_clean))
    has_scientific_notation = bool(re.search(r'\d+\.?\d*\s*√ó?\s*10[‚Åª¬π¬≤¬≥‚Å¥‚Åµ‚Å∂‚Å∑‚Å∏‚Åπ‚Å∞]*', question_clean))
    has_temperature = bool(re.search(r'\d+\s*¬∞[CF]?', question_clean))
    has_percentage = bool(re.search(r'\d+\s*%', question_clean))
    has_decimal_numbers = bool(re.search(r'\d+\.\d+', question_clean))

    # Check for practice indicators with enhanced scoring
    practice_score = 0

    # Very strong indicators (worth 4 points each)
    if any(verb in question_lower for verb in calc_verbs):
        practice_score += 4
    if has_formula:
        practice_score += 4
    if has_scientific_notation:
        practice_score += 4
    if has_calculation:
        practice_score += 4

    # Strong indicators (worth 2 points each)
    if has_numbers_with_units:
        practice_score += 2
    if has_temperature:
        practice_score += 2
    if has_percentage:
        practice_score += 2
    if has_decimal_numbers:
        practice_score += 2

    # Medium indicators (worth 1 point each)
    if any(unit in question_lower for unit in units):
        practice_score += 1
    if any(symbol in question_clean for symbol in math_symbols):
        practice_score += 1
    if any(context in question_lower for context in calc_context):
        practice_score += 1

    # Enhanced threshold - classify as PRACTICE if score >= 3
    if practice_score >= 3:
        return "PRACTICE"

    # Default: if no clear indicators, classify as THEORY
    return "THEORY"

def map_csv_type_to_our_type(csv_type: str) -> str:
    """
    Map lo·∫°i c√¢u h·ªèi t·ª´ CSV sang format c·ªßa ch√∫ng ta.
    """
    csv_type_lower = csv_type.lower().strip()
    
    if csv_type_lower == 'tr·∫Øc nghi·ªám':
        return 'MULTIPLE_CHOICE'
    elif csv_type_lower == 'b√†i t·∫≠p':
        return 'PRACTICE'
    elif csv_type_lower == 'l√Ω thuy·∫øt':
        return 'THEORY'
    else:
        return 'UNKNOWN'

def test_csv_dataset():
    """
    Test function v·ªõi dataset CSV th·ª±c t·∫ø.
    """
    print("üìä B·∫Øt ƒë·∫ßu test v·ªõi dataset CSV physics_questions_dataset.csv...")
    print("=" * 80)
    
    try:
        # ƒê·ªçc file CSV
        df = pd.read_csv('physics_questions_dataset.csv')
        print(f"‚úÖ ƒê√£ ƒë·ªçc {len(df)} c√¢u h·ªèi t·ª´ file CSV")
        
        # Th·ªëng k√™ dataset
        print(f"\nüìà TH·ªêNG K√ä DATASET:")
        type_counts = df['type'].value_counts()
        for type_name, count in type_counts.items():
            print(f"{type_name}: {count} c√¢u ({count/len(df)*100:.1f}%)")
        
        # Test tr√™n to√†n b·ªô dataset
        correct_predictions = 0
        total_tests = len(df)
        results_by_category = {
            "THEORY": {"correct": 0, "total": 0, "wrong_predictions": []},
            "PRACTICE": {"correct": 0, "total": 0, "wrong_predictions": []}, 
            "MULTIPLE_CHOICE": {"correct": 0, "total": 0, "wrong_predictions": []}
        }
        
        print(f"\nüîÑ ƒêang test {total_tests} c√¢u h·ªèi...")
        
        for index, row in df.iterrows():
            question = row['question']
            csv_type = row['type']
            expected_type = map_csv_type_to_our_type(csv_type)
            
            if expected_type == 'UNKNOWN':
                continue
                
            # Th·ª±c hi·ªán ph√¢n lo·∫°i
            predicted_type = classify_physics_question(question)
            
            # C·∫≠p nh·∫≠t th·ªëng k√™
            results_by_category[expected_type]["total"] += 1
            
            if predicted_type == expected_type:
                correct_predictions += 1
                results_by_category[expected_type]["correct"] += 1
            else:
                # L∆∞u l·∫°i c√°c d·ª± ƒëo√°n sai ƒë·ªÉ ph√¢n t√≠ch
                results_by_category[expected_type]["wrong_predictions"].append({
                    "question": question[:100] + "..." if len(question) > 100 else question,
                    "expected": expected_type,
                    "predicted": predicted_type
                })
        
        # T·ªïng k·∫øt
        print("\n" + "=" * 80)
        print("üìä K·∫æT QU·∫¢ T·ªîNG K·∫æT:")
        print(f"S·ªë test ƒë√∫ng: {correct_predictions}/{total_tests}")
        print(f"ƒê·ªô ch√≠nh x√°c t·ªïng th·ªÉ: {(correct_predictions/total_tests)*100:.1f}%")
        
        # Th·ªëng k√™ chi ti·∫øt theo t·ª´ng lo·∫°i
        print("\nüìà TH·ªêNG K√ä CHI TI·∫æT THEO LO·∫†I:")
        for category, stats in results_by_category.items():
            if stats["total"] > 0:
                accuracy = (stats["correct"] / stats["total"]) * 100
                print(f"{category}: {stats['correct']}/{stats['total']} ({accuracy:.1f}%)")
        
        # Ph√¢n t√≠ch l·ªói
        print("\nüîç PH√ÇN T√çCH L·ªñI (Top 5 m·ªói lo·∫°i):")
        for category, stats in results_by_category.items():
            if stats["wrong_predictions"]:
                print(f"\n‚ùå {category} - D·ª± ƒëo√°n sai:")
                for i, error in enumerate(stats["wrong_predictions"][:5], 1):
                    print(f"  {i}. {error['question']}")
                    print(f"     Expected: {error['expected']}, Got: {error['predicted']}")
                
                if len(stats["wrong_predictions"]) > 5:
                    print(f"     ... v√† {len(stats['wrong_predictions']) - 5} l·ªói kh√°c")
        
        # ƒê√°nh gi√° t·ªïng th·ªÉ
        overall_accuracy = (correct_predictions/total_tests)*100
        if overall_accuracy >= 90:
            print("\nüåü XU·∫§T S·∫ÆC! (‚â•90% accuracy)")
        elif overall_accuracy >= 80:
            print("\n‚úÖ T·ªêT! (‚â•80% accuracy)")
        elif overall_accuracy >= 70:
            print("\nüëç KH√Å T·ªêT! (‚â•70% accuracy)")
        elif overall_accuracy >= 60:
            print("\n‚ö†Ô∏è CH·∫§P NH·∫¨N ƒê∆Ø·ª¢C! (‚â•60% accuracy)")
        else:
            print("\n‚ùå C·∫¶N C·∫¢I THI·ªÜN! (<60% accuracy)")
            
    except FileNotFoundError:
        print("‚ùå Kh√¥ng t√¨m th·∫•y file physics_questions_dataset.csv")
    except Exception as e:
        print(f"‚ùå L·ªói khi ƒë·ªçc file: {str(e)}")

def test_sample_questions():
    """
    Test v·ªõi m·ªôt s·ªë c√¢u h·ªèi m·∫´u t·ª´ dataset.
    """
    print("\nüîç TEST M·ªòT S·ªê C√ÇU H·ªéI M·∫™U:")
    print("-" * 60)
    
    try:
        df = pd.read_csv('physics_questions_dataset.csv')
        
        # L·∫•y m·∫´u t·ª´ m·ªói lo·∫°i
        sample_questions = []
        
        for question_type in ['tr·∫Øc nghi·ªám', 'b√†i t·∫≠p', 'l√Ω thuy·∫øt']:
            type_questions = df[df['type'] == question_type].head(3)
            for _, row in type_questions.iterrows():
                sample_questions.append({
                    'question': row['question'],
                    'expected': map_csv_type_to_our_type(row['type']),
                    'csv_type': row['type']
                })
        
        for i, sample in enumerate(sample_questions, 1):
            print(f"\nüìù M·∫´u {i} ({sample['csv_type']}):")
            question = sample['question']
            if len(question) > 150:
                question = question[:150] + "..."
            print(f"C√¢u h·ªèi: {question}")
            print(f"Expected: {sample['expected']}")
            
            result = classify_physics_question(sample['question'])
            print(f"Predicted: {result}")
            
            if result == sample['expected']:
                print("‚úÖ ƒê√öNG")
            else:
                print("‚ùå SAI")
                
    except Exception as e:
        print(f"‚ùå L·ªói: {str(e)}")

if __name__ == "__main__":
    print("üöÄ CH∆Ø∆†NG TR√åNH TEST RULE-BASED CLASSIFIER V·ªöI DATASET CSV")
    print("=" * 80)
    
    # Test v·ªõi to√†n b·ªô dataset
    test_csv_dataset()
    
    # Test v·ªõi m·ªôt s·ªë c√¢u h·ªèi m·∫´u
    test_sample_questions()
    
    print("\nüëã K·∫øt th√∫c ch∆∞∆°ng tr√¨nh test!")
